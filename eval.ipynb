{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["WakV891oeL5k"],"authorship_tag":"ABX9TyOdvN1vy5Q/Dgyb30iaS8hZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"878frpF0ddKI"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50HSmI2wdd9H","executionInfo":{"status":"ok","timestamp":1714842534570,"user_tz":240,"elapsed":20470,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"31e55820-41fd-4efe-c0be-57d22ffc322e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# add to path to allow import\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/CIS6200ProjectWork/cis6200projectwork2/TempoTokens')"],"metadata":{"id":"NCPmgqAFQFzd","executionInfo":{"status":"ok","timestamp":1714842534571,"user_tz":240,"elapsed":6,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# at this point it has the exact same thing as the outer directory\n","%cd /content/gdrive/MyDrive/CIS6200ProjectWorkNOTGIT/cis6200projectwork2/TempoTokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzZz9on8dnVW","executionInfo":{"status":"ok","timestamp":1714842535266,"user_tz":240,"elapsed":699,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"c0b0e585-0244-4d54-e155-72286ec04d51"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/CIS6200ProjectWorkNOTGIT/cis6200projectwork2/TempoTokens\n"]}]},{"cell_type":"code","source":["! pip install git+https://github.com/openai/CLIP.git # get clip - this is for CLIP Score\n","\n","! pip install moviepy\n","! pip install torchaudio\n","! pip install compel\n","\n","! pip install fvcore # this one's needed for the 3d resnet model\n","! pip install av # for pytorch video - inception score and fvd score\n","! pip install \"git+https://github.com/facebookresearch/pytorchvideo.git\""],"metadata":{"id":"_bilHUKed1mS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# imports for\n","import cv2 # for reading video frames\n","import torch\n","from PIL import Image # used for casting the images for inception score, may be used for more\n","import pandas as pd # for dealing with the csv files\n","import os\n","\n","import numpy as np"],"metadata":{"id":"xneCw6fSd_FY","executionInfo":{"status":"ok","timestamp":1714842688086,"user_tz":240,"elapsed":7745,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["device = \"cpu\" # \"cuda\"\n","\n","# this is for fvd and inception score\n","model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True) # keep a copy of the model out of the class\n","model = model.eval()\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43YM2M7RT7bY","executionInfo":{"status":"ok","timestamp":1714842708717,"user_tz":240,"elapsed":20634,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"0c1b0a31-9b4a-4272-e2b4-25176270c3f0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/facebookresearch/pytorchvideo/zipball/main\" to /root/.cache/torch/hub/main.zip\n","Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/SLOW_8x8_R50.pyth\" to /root/.cache/torch/hub/checkpoints/SLOW_8x8_R50.pyth\n","100%|██████████| 248M/248M [00:08<00:00, 30.2MB/s]\n"]}]},{"cell_type":"markdown","source":["# Set up parameters and directories"],"metadata":{"id":"tpdUZ_Dlf4V1"}},{"cell_type":"code","source":["generated_vids_path = \"/content/gdrive/Shareddrives/CIS 6200 Final Project/data/Mix/dog/\" # this must be changed\n","gen_vids_npy_path = \"/content/gdrive/Shareddrives/CIS 6200 Final Project/data/Mix/mix_dog_fvd.npy\"\n","\n","# do not change these:\n","real_vids_path = \"/content/gdrive/Shareddrives/CIS 6200 Final Project/data/Dog/dog_test_video/\"\n","real_vids_npy_path = \"/content/gdrive/Shareddrives/CIS 6200 Final Project/data/Dog/dog_test_video_fvd.npy\"\n","# this one is for CLIP score\n","text_desc = \"Dog Barking\"\n","# this one is only for av align\n","audio_path = \"/content/gdrive/Shareddrives/CIS 6200 Final Project/data/Dog/dog_test_audio/\"\n"],"metadata":{"id":"3Nc8IYfBkCrn","executionInfo":{"status":"ok","timestamp":1714857531681,"user_tz":240,"elapsed":5,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["## Inception"],"metadata":{"id":"WakV891oeL5k"}},{"cell_type":"code","source":["import evaluation.Inception_Score as inceptionscore"],"metadata":{"id":"ThXl_zucfpNu","executionInfo":{"status":"ok","timestamp":1714764656540,"user_tz":240,"elapsed":3,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["cavp_inception_score_calc = inceptionscore.InceptionScoreCalculator(generated_vids_path,\n","                                                        device = device, model = model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZNUUQCmTQ5d","executionInfo":{"status":"ok","timestamp":1714764658103,"user_tz":240,"elapsed":3,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"b0519847-b17e-4a1a-8dcc-d76183524cda"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["Inception Score: Using 149 videos in directory: /content/gdrive/Shareddrives/CIS 6200 Final Project/data/volleyball/Tempotoken_CAVP_generated/\n"]}]},{"cell_type":"code","source":["cavp_inception_score_calc.calculate_inception_score_batched(splits = 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRmyqVZETo_l","executionInfo":{"status":"ok","timestamp":1714765295361,"user_tz":240,"elapsed":636054,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"7eec8fc0-24bc-4e2b-a4f5-d38aaf7c2782"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [10:35<00:00, 63.59s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["5.01893"]},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","source":["## CLIP score (working)"],"metadata":{"id":"cgx9t__teKLG"}},{"cell_type":"code","source":["import evaluation.CLIP_Score as clipscore\n","import clip"],"metadata":{"id":"CNywVDhTfSnn","executionInfo":{"status":"ok","timestamp":1714857534608,"user_tz":240,"elapsed":116,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n","_ = clip_model.eval()"],"metadata":{"id":"IBp7XwNkct6I","executionInfo":{"status":"ok","timestamp":1714857544388,"user_tz":240,"elapsed":8570,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["clipscorecalc = clipscore.CLIPScoreCalculator(generated_vids_path,\n","                                     model = clip_model, text_desc = text_desc,\n","                                     device = device)\n","clipscorecalc.calculate_clip_score()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9_WCsxweO71","executionInfo":{"status":"ok","timestamp":1714858163217,"user_tz":240,"elapsed":618836,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"18687a1c-5e81-4179-e6cd-33cb5354aa1a"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["CLIP Score: Using 100 videos in directory: /content/gdrive/Shareddrives/CIS 6200 Final Project/data/Mix/dog/\n","Using text description: Dog Barking\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [10:18<00:00,  6.19s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.2283387390275796"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["# AV-Align"],"metadata":{"id":"3YqBoPpbeDdx"}},{"cell_type":"code","source":["import av_align as av_score"],"metadata":{"id":"3_vsnnwjls2I","executionInfo":{"status":"ok","timestamp":1714858163220,"user_tz":240,"elapsed":55,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# get wav files\n","video_dir = generated_vids_path\n","filenames = [i[:-6] for i in os.listdir(video_dir) if (i[-6:] == '_c.mp4')]\n","audio_dir = audio_path # directory with input audios of the form filename.wav"],"metadata":{"id":"7m7t1DlppDta","executionInfo":{"status":"ok","timestamp":1714858163222,"user_tz":240,"elapsed":49,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["score = 0\n","for file in filenames:\n","\n","    video_path = f'{video_dir}{file}_c.mp4'\n","    print(video_path)\n","    audio_path = f'{audio_dir}{file}.wav'\n","    print(audio_path)\n","\n","    frames, fps = av_score.extract_frames(video_path)\n","\n","    audio_peaks = av_score.detect_audio_peaks(audio_path)\n","    flow_trajectory, video_peaks = av_score.detect_video_peaks(frames, fps)\n","\n","    score += av_score.calc_intersection_over_union(audio_peaks, video_peaks, fps)\n","\n","print(\"Done!\")\n","print('AV-Align: ', score/len(filenames))"],"metadata":{"id":"NhicyE3Xkj0f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# FVD Score"],"metadata":{"id":"9MiFq6f0NjlH"}},{"cell_type":"code","source":["model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\n","device = \"cpu\"\n","model = model.to(device)\n","_ = model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHb6peohNlSA","executionInfo":{"status":"ok","timestamp":1714858465535,"user_tz":240,"elapsed":3801,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"e0f60f79-c1e4-457c-c551-924ceb26a181"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"]}]},{"cell_type":"code","source":["from scipy.linalg import sqrtm\n","import os\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from PIL import Image\n","import numpy as np\n","from scipy.stats import entropy\n","import os\n","from tqdm import tqdm\n","from pytorchvideo.data.encoded_video import EncodedVideo\n","\n","from torchvision.transforms import Compose, Lambda\n","from torchvision.transforms._transforms_video import (\n","    CenterCropVideo,\n","    NormalizeVideo,\n",")\n","from pytorchvideo.transforms import (\n","    ApplyTransformToKey,\n","    ShortSideScale,\n","    UniformTemporalSubsample\n",")\n","\n","class VideoBatchPrepper:\n","\n","    def __init__(self, vid_dir_path, device = \"cpu\", model = None):\n","        self.device = device\n","\n","        if model is None:\n","            self.model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\n","            self.model = self.model.eval()\n","            self.model = self.model.to(self.device)\n","        else:\n","            self.model = model # assumes that self.model has been set to eval mode and sent to device already\n","\n","        # specified for the model\n","        self.side_size = 256\n","        self.mean = [0.45, 0.45, 0.45]\n","        self.std = [0.225, 0.225, 0.225]\n","        self.crop_size = 256\n","        self.num_frames = 8\n","        self.sampling_rate = 8\n","        self.frames_per_second = 30\n","\n","        self.transform =  ApplyTransformToKey(\n","            key=\"video\",\n","            transform=Compose(\n","                [\n","                    UniformTemporalSubsample(self.num_frames),\n","                    Lambda(lambda x: x/255.0),\n","                    NormalizeVideo(self.mean, self.std),\n","                    ShortSideScale(\n","                        size=self.side_size\n","                    ),\n","                    CenterCropVideo(crop_size=(self.crop_size, self.crop_size))\n","                ]\n","            ),\n","        )\n","\n","        self.clip_duration = (self.num_frames * self.sampling_rate)/self.frames_per_second\n","\n","        self.start_sec = 0 # should correspond to where the action happens in the video, but set to 0 for this.\n","        self.end_sec = self.start_sec + self.clip_duration\n","\n","        # get the videos\n","        self.vid_dir_path = vid_dir_path\n","        self.vid_names = [i for i in os.listdir(vid_dir_path) if (i[-4:] == '.mp4')]\n","        print(f\"Video Batch Preparer: Using {len(self.vid_names)} videos in directory: {self.vid_dir_path}\")\n","\n","    def get_video_batch(self, batch_start = 0, batch_end = None):\n","        if batch_end is None:\n","            batch_end = len(self.vid_names)\n","        vid_data_tgt = []\n","        for vid_name in self.vid_names[batch_start:batch_end]:\n","          vid_file_path = self.vid_dir_path + vid_name\n","          vid_data = self.transform(EncodedVideo.from_path(vid_file_path).get_clip(start_sec=self.start_sec,end_sec=self.end_sec))[\"video\"]\n","          vid_data_tgt.append(vid_data)\n","        return(torch.stack(vid_data_tgt)) # end user must put it on the device"],"metadata":{"id":"nXlfK5G8Q6ss","executionInfo":{"status":"ok","timestamp":1714858465536,"user_tz":240,"elapsed":25,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["real_vid_dir_path = real_vids_path\n","real_vid_names = [i for i in os.listdir(real_vid_dir_path) if (i[-4:] == '.mp4')]\n","real_vb = VideoBatchPrepper(real_vid_dir_path, device = \"cuda\", model = model) # this is the exact same thing as for the inception score\n","\n","real_features = np.zeros((len(real_vid_names), 400)) # we know it's 8192 bc thats what the model automatically pools to\n","batch_size = 4\n","if len(real_vid_names) % batch_size != 0:\n","  num_batches = len(real_vid_names) // batch_size + 1\n","else:\n","  num_batches = len(real_vid_names) // batch_size\n","for i in tqdm(range(num_batches)):\n","  start_idx = i * batch_size\n","  end_idx = (i + 1) * batch_size if i < num_batches - 1 else len(real_vid_names)\n","  realbatch1 = real_vb.get_video_batch(batch_start = start_idx, batch_end = end_idx) # todo: copy and paste this code into the fvd thing too, clean up\n","  realbatch1 = realbatch1.to(device)\n","  with torch.no_grad():\n","    testres = model(realbatch1)\n","  testres = testres.cpu().numpy()\n","  real_features[start_idx:end_idx, :] = testres\n","print(f\"\\nsaving to: {real_vids_npy_path}\")\n","np.save(real_vids_npy_path, real_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXH55tiETzou","executionInfo":{"status":"ok","timestamp":1714858856496,"user_tz":240,"elapsed":390984,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"08c0886f-c96e-4b68-e95e-1c62f7a5f53f"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Video Batch Preparer: Using 101 videos in directory: /content/gdrive/Shareddrives/CIS 6200 Final Project/data/Dog/dog_test_video/\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26/26 [06:30<00:00, 15.02s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","saving to: /content/gdrive/Shareddrives/CIS 6200 Final Project/data/Dog/dog_test_video_fvd.npy\n"]}]},{"cell_type":"code","source":["real_features = np.load(real_vids_npy_path)"],"metadata":{"id":"oAmO4_keW3hE","executionInfo":{"status":"ok","timestamp":1714860092135,"user_tz":240,"elapsed":124,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["gen_vid_dir_path = generated_vids_path\n","gen_vid_names = [i for i in os.listdir(gen_vid_dir_path) if (i[-4:] == '.mp4')]\n","gen_vb = VideoBatchPrepper(gen_vid_dir_path, device = \"cuda\", model = model) # this is the exact same thing as for the inception score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BMd1qYa4UFSp","executionInfo":{"status":"ok","timestamp":1714858856642,"user_tz":240,"elapsed":170,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"c9a4f2f7-0169-431f-9547-32dc7fd1bcf9"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Video Batch Preparer: Using 100 videos in directory: /content/gdrive/Shareddrives/CIS 6200 Final Project/data/Mix/dog/\n"]}]},{"cell_type":"code","source":["gen_features = np.zeros((len(gen_vid_names), 400))\n","batch_size = 4\n","if len(gen_vid_names) % batch_size != 0:\n","  num_batches = len(gen_vid_names) // batch_size + 1\n","else:\n","  num_batches = len(gen_vid_names) // batch_size\n","for i in tqdm(range(num_batches)):\n","  start_idx = i * batch_size\n","  end_idx = (i + 1) * batch_size if i < num_batches - 1 else len(gen_vid_names)\n","  batch = gen_vb.get_video_batch(batch_start = start_idx, batch_end = end_idx) # todo: copy and paste this code into the fvd thing too, clean up\n","  batch = batch.to(device)\n","  with torch.no_grad():\n","    res = model.forward(batch)\n","  res = res.cpu().numpy() # these are the features\n","  gen_features[start_idx:end_idx, :] = res\n","print(f\"\\nsaving to: {gen_vids_npy_path}\")\n","np.save(gen_vids_npy_path, gen_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJlYnSqPUWt7","executionInfo":{"status":"ok","timestamp":1714859117425,"user_tz":240,"elapsed":260802,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"c845e36f-d732-4885-8d7d-5c10edb5956c"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 25/25 [04:20<00:00, 10.43s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","saving to: /content/gdrive/Shareddrives/CIS 6200 Final Project/data/Mix/mix_dog_fvd.npy\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# optional:\n","# gen_features = np.load(gen_vids_npy_path)"],"metadata":{"id":"TNry4uWCUTFc","executionInfo":{"status":"ok","timestamp":1714852406406,"user_tz":240,"elapsed":22,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# get the mean and covariance of real features\n","realmean = np.mean(real_features, axis = 0)\n","realcov = np.cov(real_features, rowvar = False)\n","# get mean and cov of generated features\n","genmean = np.mean(gen_features, axis = 0)\n","gencov = np.cov(gen_features, rowvar = False)"],"metadata":{"id":"P8JcKwb7UdvM","executionInfo":{"status":"ok","timestamp":1714859117426,"user_tz":240,"elapsed":73,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["ssdiff = np.sum((realmean - genmean)**2)\n","covmean = sqrtm(realcov @ gencov, disp = False)[0]\n","if np.iscomplexobj(covmean):\n","    covmean = covmean.real\n","\n","fvd = ssdiff + np.trace(realcov + gencov - 2 * covmean)\n","print(fvd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnp4oNqEUiX_","executionInfo":{"status":"ok","timestamp":1714859117818,"user_tz":240,"elapsed":452,"user":{"displayName":"Erica Wu","userId":"11583198898505868030"}},"outputId":"8b4b7d05-bb8a-41c8-82b8-1c3f3992145e"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["-1744828002.4575338\n"]}]}]}